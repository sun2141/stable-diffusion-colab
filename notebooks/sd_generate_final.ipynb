{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c45565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 설치 & 런타임 자동 재시작\n",
    "!pip install --quiet \\\n",
    "  diffusers==0.26.3 \\\n",
    "  transformers==4.39.3 \\\n",
    "  huggingface_hub==0.25.1 \\\n",
    "  accelerate==0.29.2 \\\n",
    "  gradio==3.50.2 \\\n",
    "  peft==0.10.0 \\\n",
    "  safetensors torch torchvision torchaudio numpy scipy\n",
    "\n",
    "import os, IPython\n",
    "print(\"✅ 설치 완료. 런타임을 자동으로 재시작합니다.\")\n",
    "os.kill(os.getpid(), 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Hugging Face 로그인\n",
    "from huggingface_hub import login\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e342fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 모델 로딩\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "import torch\n",
    "\n",
    "pipe_txt2img = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287b0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 이미지 생성 함수\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def infer(prompt, init_image=None, strength=0.75):\n",
    "    if init_image is not None:\n",
    "        if isinstance(init_image, np.ndarray):\n",
    "            init_image = Image.fromarray(init_image)\n",
    "        elif not isinstance(init_image, Image.Image):\n",
    "            raise ValueError(f\"Unsupported image type: {type(init_image)}\")\n",
    "        init_image = init_image.resize((512, 512))\n",
    "\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            result = pipe_img2img(\n",
    "                prompt=[prompt],\n",
    "                image=init_image,\n",
    "                strength=strength,\n",
    "                guidance_scale=7.5\n",
    "            )\n",
    "    else:\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            result = pipe_txt2img(\n",
    "                prompt=[prompt],\n",
    "                guidance_scale=7.5\n",
    "            )\n",
    "    return result.images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c820eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Gradio 인터페이스 구성\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 🎨 Stable Diffusion Image Generator\")\n",
    "\n",
    "    prompt_input = gr.Textbox(label=\"프롬프트\", value=\"a cushion on a car seat\")\n",
    "    init_image = gr.Image(label=\"초기 이미지 (선택)\", type=\"numpy\")\n",
    "    strength = gr.Slider(label=\"유지 강도\", minimum=0.0, maximum=1.0, value=0.75)\n",
    "    gallery = gr.Gallery(label=\"결과 이미지\")\n",
    "\n",
    "    run_button = gr.Button(\"이미지 생성\")\n",
    "\n",
    "    run_button.click(fn=infer, inputs=[prompt_input, init_image, strength], outputs=[gallery])\n",
    "\n",
    "demo.launch(debug=True, share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
